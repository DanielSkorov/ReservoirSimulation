#!/usr/bin/env python
# coding: utf-8

# <a id='math-om-tunneling'></a>
# # Туннельный метод оптимизации функции
# Рассмотренными в предыдущих разделах [методом Ньютона](./OM-1-Newton.html#math-om-newton) и [квази-ньютоновскими методами](./OM-2-QNewton.html#math-om-qnewton) решалась задача поиска стационарной точки функции, в которой ее частные производные по независимым переменным равнялись нулю. Однако зачастую требуется определить глобальный минимум или глобальный максимум функции нескольких переменных. Под глобальным минимумом (или максимумом) функции будет пониматься такая стационарная точка функции, в которой ее значение принимает минимальное (или максимальное) значение на всей области ее определения. Поскольку глобальный минимум (или максимум) функции также является ее стационарной точкой, то в ней частные производные функции по независисым переменным тоже равняются нулю. Следовательно, к нахождению глобального минимума (или максимума) функции можно подойти с точки зрения перебора всех стационарных точек функции и сравнения ее значения в них \[[Anderssen et al, 1975](https://doi.org/10.1007/BF00933849)\]. Однако данный подход может быть неудобным, поскольку предполагает задание большого количества начальных приближений для схождения алгоритма ко всем возможным стационарным точкам функции. Вместо этого существуют численные методы, направленные на нахождение глобального минимума или глоабльного максимума функции, то есть ее оптимизации. В данном разделе будет рассматриваться туннельный метод оптимизации функции. В качестве основы для составления данного раздела использовалась информация, изложенная в работах \[[Levy and Montalvo, 1985](https://doi.org/10.1137/0906002); [Barron and Gomez, 1991](https://www.researchgate.net/publication/313196925_The_exponential_tunneling_method); [Zamir and Ahmad, 2012](https://www.researchgate.net/publication/263544631_Classical_Tunneling_Function_versus_Exponential_Tunneling_Function_in_Tunneling_Algorithm); [Caravelli et al, 2021](https://doi.org/10.1126/sciadv.abh1542)\].

# Туннельный метод оптимизации функции $f \left( \vec{x} \right)$ состоит из двух фаз. На первой фазе для произвольно выбранного начального приближения $\vec{x_0}$ решается задача определения стационарной точки (локального минимума или максимума) $\vec{x_0^*}$ с использованием любого алгоритма определения стационарной точки, например, [метода Ньютона](./OM-1-Newton.ipynb#math-om-newton). Далее, на второй фазе, определяется такое значение $\vec{x_1}$, при котором $ f \left( \vec{x_1} \right) \leq f \left( \vec{x_0^*} \right)$ при поиске минимума функции или $ f \left( \vec{x_1} \right) \geq f \left( \vec{x_0^*} \right)$ при поиске максимума функции. После этого найденное значение $\vec{x_1}$ используется в качестве начального приближения для нахождения нового локального минимума $\vec{x_1^*}$ (или максимума) функции $f \left( \vec{x} \right)$. В результате, данная процедура повторяется до тех пор, пока не будет найден глобальный минимум или максимум функции.

# Подробнее остановимся на второй фазе - фазе туннелирования, то есть определения нового значения $\vec{x_1}$, при котором $ f \left( \vec{x_1} \right) \leq f \left( \vec{x_0^*} \right)$, причем $\vec{x_1}$ должен находиться в районе другой "впадины" рассматриваемой функции (здесь и далее будем рассматривать задачу определения глобального минимума функции). Для решения данной задачи необходимо "заменить" уже найденный локальный минимум функции [полюсом](https://en.wikipedia.org/wiki/Zeros_and_poles). Для этого необходимо создать новую функцию $T \left( \vec{x} \right)$, записанную в следующем виде:
# 
# $$ T_0 \left( \vec{x} \right) = \left(f \left( \vec{x} \right) - f \left( \vec{x_0^*} \right) \right) P \left( \vec{x}, \vec{x_0^*}, \lambda \right). $$
# 
# Или в общем виде для $K$-го найденного локального минимума:
# 
# $$ T \left( \vec{x} \right) = \left( f \left( \vec{x} \right) - f \left( \vec{x_K^*} \right) \right) \prod_{i=1}^K P \left( \vec{x}, \vec{x_i^*}, \lambda \right). $$
# 
# Функция $ P \left( \vec{x}, \vec{x_i^*}, \lambda \right) $ определяется одним из двух способов. В *классическом* туннельном методе \[[Levy and Montalvo, 1985](https://doi.org/10.1137/0906002)\]:
# 
# $$ P \left( \vec{x}, \vec{x_i^*}, \lambda \right) = \left| \left| \vec{x} - \vec{x_i^{*}} \right| \right|^{-\lambda}, $$
# 
# где $\left| \left| \vec{x} \right| \right|$ обозначает [норму](https://en.wikipedia.org/wiki/Norm_(mathematics)) или [длину](../1-LAB/LAB-2-VectorOperations.ipynb#math-lab-vector_operations) вектора $\vec{x}$. В *экспоненциальном* туннельном методе [Barron and Gomez, 1991](https://www.researchgate.net/publication/313196925_The_exponential_tunneling_method):
# 
# $$ P \left( \vec{x}, \vec{x_i^*}, \lambda \right) = exp \left(\frac{\lambda}{\left| \left| \vec{x} - \vec{x_i^*} \right| \right|} \right). $$
# 
# Параметр $\lambda$ имеет важное значение в туннельном методе. Если локальный минимум функции был определен недостаточно точно, то малые значения $\lambda$ не позволят создать полюс функции. С другой стороны, большие значения параметра $\lambda$ приводят к выполаживанию функции $T \left( \vec{x} \right)$, что негативно сказывается на скорости поиска следующего локального минимума функции. Базовое значение параметра $\lambda = 1$. Однако это значение может быть увеличено в том случае, если локальный минимум функции $ f \left( \vec{x} \right) $ был определен недостаточно точно, до тех пор, пока не получится найти начальное приближение к туннелированию, при котором значение функции $ T \left( \vec{x} \right) $ отрицательно.

# Еще одним важным этапом в рассматриваемом алгоритме является инициализация туннелирования начальным значением. Поскольку в точке $\vec{x_i^*}$ искусственно создается полюс функции, в котором она стремится к бесконечности, то необходимо задать другое начальное приближение для туннелирования, находящееся поблизости с найденным локальным минимумом $\vec{x_i^*}$. После этого осуществляется стадия туннелирования до тех пор, пока не находится новый локальный минимум, при котором $T \left( \vec{x_{i+1}^*} \right) \leq 0$. Если туннелирование не было достигнуто, создается следующее начальная точка и алгоритм повторяется до тех пор, пока не будут опробованы $2 n$ начальных приближений, где $n$ - размерность вектора $\vec{x}$. После этого, при необходимости, генерируются рандомные значения начальных точек $\vec{x}$ до тех пор, пока не будет достигнуто максимальное количество итераций.

# В процессе туннелирования могут быть достигнуты стационарные точки $\vec{x_s^*}$ функции $T \left( \vec{x} \right)$, в которых ее частные производные по $\vec{x}$ равны нулю. В этом случае функция $T \left( \vec{x} \right)$ модифицируется путем добавления мобильного полюса:
# 
# $$ T \left( \vec{x} \right) = \left( f \left( \vec{x} \right) - f \left( \vec{x_K^*} \right) \right) P \left( \vec{x}, \vec{x_s^*}, \lambda_s \right) \prod_{i=1}^K P \left( \vec{x}, \vec{x_i^*}, \lambda \right). $$
# 
# Мобильные полюсы помещаются в те места, где были обнаружены стационарные точки функции $T \left( \vec{x} \right)$; после ухода от стационарной точки мобильный полюс может быть убран путем приравнивания $\lambda_s$ к нулю.

# Алгоритм туннельного метода останавливается после того, как:
# * опробованы все $2n$ вариантов инициализации новой итерации туннелирования для максимального значения $\lambda_{max} = 5$;
# * достигнуто максимальное количество итераций инициализации туннелирований;
# * достигнута нижняя граница целевой функции $f \left( \vec{x} \right)$.

# Рассмотрим применение туннельного метода на следующей задаче. Пусть имеется функция:
# 
# $$ f \left( \vec{x} \right) = \frac{1}{2} \sum_{i=1}^{n} \left( x_i^4 - 16 x_i^2 + 5 x_i \right) $$
# 
# с размерностью $n=2$. Необходимо определить глобальный минимум функции, задавшись начальным приближением $\vec{x_0} = \left\{ 4.0; \; 6.4 \right\}$.
